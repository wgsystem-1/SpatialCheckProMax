# SpatialCheckProMax AI 학습 매뉴얼

| 항목 | 내용 |
|------|------|
| 문서 버전 | 1.0 |
| 작성일 | 2026-01-04 |
| 작성자 | (주)우리강산시스템 |

---

## 1. 개요

### 1.1 목적

본 문서는 SpatialCheckProMax v2.0에서 사용하는 AI 모델(GeometryGNN)의 학습 방법, 데이터 준비, 모델 배포 과정을 설명합니다.

### 1.2 대상 독자

- AI/ML 엔지니어
- 모델 학습 담당자
- 시스템 운영자

### 1.3 전제 조건

- Python 3.10 이상
- PyTorch 2.0 이상
- CUDA 지원 GPU (권장)
- 기본적인 딥러닝 지식

---

## 2. AI 모델 개요

### 2.1 모델 아키텍처

| 항목 | 내용 |
|------|------|
| **모델명** | GeometryGNN (Graph Neural Network) |
| **입력** | 지오메트리 좌표 시퀀스 |
| **출력** | 좌표 보정 오프셋 (dx, dy) |
| **목적** | 지오메트리 오류 자동 수정 |

### 2.2 모델 구조

```
입력 좌표 [batch, vertices, 2]
           │
           ▼
┌─────────────────────────┐
│   Coordinate Encoder    │
│   (Linear + LayerNorm)  │
└─────────────────────────┘
           │
           ▼
┌─────────────────────────┐
│   Graph Attention Layer │
│   (Multi-Head Attention)│
│   × N layers            │
└─────────────────────────┘
           │
           ▼
┌─────────────────────────┐
│   Offset Decoder        │
│   (Linear + Tanh)       │
└─────────────────────────┘
           │
           ▼
출력 오프셋 [batch, vertices, 2]
```

### 2.3 핵심 아이디어

1. **좌표 임베딩**: 각 좌표점을 고차원 벡터로 임베딩
2. **그래프 어텐션**: 인접 좌표 간 관계 학습
3. **오프셋 예측**: 각 좌표의 보정량 예측
4. **보정 적용**: `corrected = original + offset`

---

## 3. 학습 환경 구성

### 3.1 필수 패키지

```bash
# requirements.txt
torch>=2.0.0
torch-geometric>=2.3.0
numpy>=1.24.0
shapely>=2.0.0
geopandas>=0.13.0
onnx>=1.14.0
onnxruntime>=1.15.0
tqdm>=4.65.0
tensorboard>=2.13.0
```

### 3.2 환경 설치

```bash
# Conda 환경 생성
conda create -n geometry_gnn python=3.10
conda activate geometry_gnn

# PyTorch 설치 (CUDA 11.8)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# 기타 패키지 설치
pip install -r requirements.txt
```

### 3.3 디렉터리 구조

```
ai_training/
├── data/                      # 학습 데이터
│   ├── raw/                   # 원본 GDB 파일
│   ├── processed/             # 전처리된 데이터
│   └── splits/                # 학습/검증/테스트 분할
├── models/                    # 모델 정의
│   ├── geometry_gnn.py        # GeometryGNN 모델
│   └── layers.py              # 커스텀 레이어
├── scripts/                   # 학습 스크립트
│   ├── prepare_data.py        # 데이터 준비
│   ├── train.py               # 학습 실행
│   ├── evaluate.py            # 평가
│   └── export_onnx.py         # ONNX 변환
├── configs/                   # 설정 파일
│   └── train_config.yaml      # 학습 설정
├── outputs/                   # 출력
│   ├── checkpoints/           # 체크포인트
│   ├── logs/                  # 텐서보드 로그
│   └── exports/               # ONNX 모델
└── requirements.txt
```

---

## 4. 학습 데이터 준비

### 4.1 데이터 수집

학습 데이터는 다음 쌍으로 구성됩니다:

| 데이터 | 설명 |
|-------|------|
| **오류 지오메트리** | 검수에서 발견된 오류가 있는 지오메트리 |
| **정답 지오메트리** | 전문가가 수정한 올바른 지오메트리 |

### 4.2 데이터 형식

```python
# 학습 데이터 예시 (JSON)
{
    "samples": [
        {
            "id": "sample_001",
            "error_type": "self_intersection",
            "original_coords": [[x1, y1], [x2, y2], ...],
            "corrected_coords": [[x1', y1'], [x2', y2'], ...],
            "geometry_type": "Polygon"
        },
        ...
    ]
}
```

### 4.3 데이터 전처리

```python
# prepare_data.py
import json
import numpy as np
from shapely.geometry import shape
from shapely.validation import explain_validity

def preprocess_geometry(coords, max_vertices=500):
    """좌표 정규화 및 패딩"""
    n = len(coords)

    if n > max_vertices:
        return None  # 정점 수 초과

    # 정규화 (중심 이동 + 스케일링)
    coords = np.array(coords)
    center = coords.mean(axis=0)
    coords = coords - center
    scale = np.abs(coords).max()
    if scale > 0:
        coords = coords / scale

    # 패딩
    padded = np.zeros((max_vertices, 2))
    padded[:n] = coords

    # 마스크
    mask = np.zeros(max_vertices)
    mask[:n] = 1

    return {
        'coords': padded,
        'mask': mask,
        'center': center,
        'scale': scale,
        'original_length': n
    }
```

### 4.4 데이터 분할

```python
# 학습:검증:테스트 = 8:1:1
from sklearn.model_selection import train_test_split

train_data, temp_data = train_test_split(all_data, test_size=0.2, random_state=42)
val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)
```

---

## 5. 모델 학습

### 5.1 모델 정의

```python
# models/geometry_gnn.py
import torch
import torch.nn as nn
import torch.nn.functional as F

class GeometryGNN(nn.Module):
    def __init__(self,
                 input_dim=2,
                 hidden_dim=128,
                 num_heads=8,
                 num_layers=4,
                 max_vertices=500):
        super().__init__()

        self.max_vertices = max_vertices

        # 좌표 인코더
        self.coord_encoder = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.ReLU()
        )

        # 그래프 어텐션 레이어
        self.attention_layers = nn.ModuleList([
            nn.MultiheadAttention(hidden_dim, num_heads, batch_first=True)
            for _ in range(num_layers)
        ])

        self.layer_norms = nn.ModuleList([
            nn.LayerNorm(hidden_dim)
            for _ in range(num_layers)
        ])

        # 오프셋 디코더
        self.offset_decoder = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 2),
            nn.Tanh()  # 오프셋 범위 제한
        )

        # 스케일 파라미터 (학습 가능)
        self.offset_scale = nn.Parameter(torch.tensor(0.1))

    def forward(self, coordinates, mask):
        """
        Args:
            coordinates: [batch, max_vertices, 2]
            mask: [batch, max_vertices]
        Returns:
            offsets: [batch, max_vertices, 2]
        """
        # 좌표 인코딩
        x = self.coord_encoder(coordinates)

        # 어텐션 마스크 생성
        attn_mask = (mask == 0)  # True = 패딩 위치

        # 그래프 어텐션 적용
        for attn, ln in zip(self.attention_layers, self.layer_norms):
            residual = x
            x, _ = attn(x, x, x, key_padding_mask=attn_mask)
            x = ln(x + residual)

        # 오프셋 예측
        offsets = self.offset_decoder(x)
        offsets = offsets * self.offset_scale

        # 패딩 위치는 0으로 마스킹
        offsets = offsets * mask.unsqueeze(-1)

        return offsets
```

### 5.2 손실 함수

```python
class GeometryLoss(nn.Module):
    def __init__(self, lambda_smooth=0.1, lambda_valid=0.5):
        super().__init__()
        self.lambda_smooth = lambda_smooth
        self.lambda_valid = lambda_valid

    def forward(self, pred_offsets, target_offsets, mask, original_coords):
        """
        Args:
            pred_offsets: 예측 오프셋 [batch, vertices, 2]
            target_offsets: 정답 오프셋 [batch, vertices, 2]
            mask: 유효 마스크 [batch, vertices]
            original_coords: 원본 좌표 [batch, vertices, 2]
        """
        # 1. 좌표 손실 (MSE)
        coord_loss = F.mse_loss(
            pred_offsets * mask.unsqueeze(-1),
            target_offsets * mask.unsqueeze(-1)
        )

        # 2. 스무딩 손실 (인접 오프셋 간 차이)
        smooth_loss = self._smoothness_loss(pred_offsets, mask)

        # 3. 유효성 손실 (지오메트리 유효성)
        valid_loss = self._validity_loss(
            original_coords + pred_offsets,
            mask
        )

        total_loss = (
            coord_loss +
            self.lambda_smooth * smooth_loss +
            self.lambda_valid * valid_loss
        )

        return total_loss, {
            'coord_loss': coord_loss.item(),
            'smooth_loss': smooth_loss.item(),
            'valid_loss': valid_loss.item()
        }

    def _smoothness_loss(self, offsets, mask):
        """인접 오프셋 간 차이 최소화"""
        diff = offsets[:, 1:] - offsets[:, :-1]
        mask_diff = mask[:, 1:] * mask[:, :-1]
        return (diff.pow(2).sum(-1) * mask_diff).mean()

    def _validity_loss(self, coords, mask):
        """간단한 유효성 검사 (교차 방지)"""
        # 구현 생략 - 실제로는 Shapely 사용
        return torch.tensor(0.0)
```

### 5.3 학습 스크립트

```python
# scripts/train.py
import torch
from torch.utils.data import DataLoader
from tqdm import tqdm

def train_epoch(model, dataloader, optimizer, criterion, device):
    model.train()
    total_loss = 0

    for batch in tqdm(dataloader, desc="Training"):
        coords = batch['original_coords'].to(device)
        target = batch['target_offsets'].to(device)
        mask = batch['mask'].to(device)

        optimizer.zero_grad()

        pred_offsets = model(coords, mask)
        loss, metrics = criterion(pred_offsets, target, mask, coords)

        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()

        total_loss += loss.item()

    return total_loss / len(dataloader)

def main():
    # 설정
    config = {
        'batch_size': 32,
        'learning_rate': 1e-4,
        'epochs': 100,
        'hidden_dim': 128,
        'num_heads': 8,
        'num_layers': 4
    }

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # 모델 초기화
    model = GeometryGNN(
        hidden_dim=config['hidden_dim'],
        num_heads=config['num_heads'],
        num_layers=config['num_layers']
    ).to(device)

    optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'])
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['epochs'])
    criterion = GeometryLoss()

    # 데이터 로더
    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'])

    best_val_loss = float('inf')

    for epoch in range(config['epochs']):
        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)
        val_loss = validate(model, val_loader, criterion, device)

        scheduler.step()

        print(f"Epoch {epoch+1}/{config['epochs']}")
        print(f"  Train Loss: {train_loss:.6f}")
        print(f"  Val Loss: {val_loss:.6f}")

        # 최적 모델 저장
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': val_loss,
            }, 'outputs/checkpoints/best_model.pt')

if __name__ == '__main__':
    main()
```

---

## 6. 모델 평가

### 6.1 평가 지표

| 지표 | 설명 |
|------|------|
| **MSE** | 예측 오프셋과 정답 오프셋 간 평균 제곱 오차 |
| **Validity Rate** | 수정 후 유효한 지오메트리 비율 |
| **Type Preservation** | 원본 타입이 유지되는 비율 |
| **Hausdorff Distance** | 원본과 수정본 간 형상 유사도 |

### 6.2 평가 스크립트

```python
# scripts/evaluate.py
from shapely.geometry import Polygon, LineString
from shapely.validation import make_valid

def evaluate_model(model, test_loader, device):
    model.eval()

    metrics = {
        'mse': [],
        'validity_rate': [],
        'type_preserved': [],
        'hausdorff': []
    }

    with torch.no_grad():
        for batch in test_loader:
            coords = batch['original_coords'].to(device)
            mask = batch['mask'].to(device)
            target = batch['target_offsets'].to(device)
            geom_types = batch['geometry_type']

            pred_offsets = model(coords, mask)
            corrected_coords = coords + pred_offsets

            # MSE
            mse = F.mse_loss(pred_offsets * mask.unsqueeze(-1),
                           target * mask.unsqueeze(-1))
            metrics['mse'].append(mse.item())

            # 지오메트리별 검증
            for i in range(len(coords)):
                result = evaluate_single_geometry(
                    coords[i].cpu().numpy(),
                    corrected_coords[i].cpu().numpy(),
                    mask[i].cpu().numpy(),
                    geom_types[i]
                )
                metrics['validity_rate'].append(result['valid'])
                metrics['type_preserved'].append(result['type_preserved'])
                metrics['hausdorff'].append(result['hausdorff'])

    return {k: np.mean(v) for k, v in metrics.items()}
```

---

## 7. ONNX 변환 및 배포

### 7.1 ONNX 변환

```python
# scripts/export_onnx.py
import torch
import json

def export_to_onnx(model, output_path, max_vertices=500):
    model.eval()

    # 더미 입력
    dummy_coords = torch.randn(1, max_vertices, 2)
    dummy_mask = torch.ones(1, max_vertices)

    # ONNX 변환
    torch.onnx.export(
        model,
        (dummy_coords, dummy_mask),
        output_path,
        input_names=['coordinates', 'mask'],
        output_names=['offsets'],
        dynamic_axes={
            'coordinates': {0: 'batch_size'},
            'mask': {0: 'batch_size'},
            'offsets': {0: 'batch_size'}
        },
        opset_version=14
    )

    print(f"모델 저장 완료: {output_path}")

    # 메타데이터 저장
    metadata = {
        "ModelName": "GeometryGNN",
        "Version": "1.0.0",
        "Created": datetime.now().isoformat(),
        "MaxVertices": max_vertices,
        "InputSpec": {
            "coordinates": "[batch, max_vertices, 2]",
            "mask": "[batch, max_vertices]"
        },
        "OutputSpec": {
            "offsets": "[batch, max_vertices, 2]"
        }
    }

    metadata_path = output_path.replace('.onnx', '_metadata.json')
    with open(metadata_path, 'w') as f:
        json.dump(metadata, f, indent=2)

    print(f"메타데이터 저장 완료: {metadata_path}")

if __name__ == '__main__':
    # 모델 로드
    checkpoint = torch.load('outputs/checkpoints/best_model.pt')
    model = GeometryGNN()
    model.load_state_dict(checkpoint['model_state_dict'])

    # ONNX 변환
    export_to_onnx(model, 'outputs/exports/geometry_corrector.onnx')
```

### 7.2 ONNX 검증

```python
import onnxruntime as ort
import numpy as np

def verify_onnx(onnx_path):
    # ONNX 세션 로드
    session = ort.InferenceSession(onnx_path)

    # 테스트 입력
    coords = np.random.randn(1, 500, 2).astype(np.float32)
    mask = np.ones((1, 500), dtype=np.float32)

    # 추론
    outputs = session.run(
        None,
        {'coordinates': coords, 'mask': mask}
    )

    offsets = outputs[0]
    print(f"출력 형상: {offsets.shape}")
    print(f"오프셋 범위: [{offsets.min():.4f}, {offsets.max():.4f}]")

    return True
```

### 7.3 배포

```bash
# 모델 파일 복사
cp outputs/exports/geometry_corrector.onnx \
   ../SpatialCheckProMax/Resources/Models/

cp outputs/exports/geometry_corrector_metadata.json \
   ../SpatialCheckProMax/Resources/Models/model_metadata.json
```

---

## 8. 하이퍼파라미터 튜닝

### 8.1 주요 하이퍼파라미터

| 파라미터 | 기본값 | 권장 범위 | 설명 |
|---------|-------|----------|------|
| hidden_dim | 128 | 64-256 | 히든 레이어 차원 |
| num_heads | 8 | 4-16 | 어텐션 헤드 수 |
| num_layers | 4 | 2-6 | 어텐션 레이어 수 |
| learning_rate | 1e-4 | 1e-5 ~ 1e-3 | 학습률 |
| batch_size | 32 | 16-64 | 배치 크기 |
| lambda_smooth | 0.1 | 0.01-1.0 | 스무딩 손실 가중치 |

### 8.2 권장 설정

```yaml
# configs/train_config.yaml
model:
  hidden_dim: 128
  num_heads: 8
  num_layers: 4
  max_vertices: 500

training:
  batch_size: 32
  learning_rate: 1e-4
  epochs: 100
  weight_decay: 0.01
  warmup_epochs: 5

loss:
  lambda_smooth: 0.1
  lambda_valid: 0.5

data:
  train_ratio: 0.8
  val_ratio: 0.1
  test_ratio: 0.1
```

---

## 9. 문제 해결

### 9.1 학습 시 발생하는 문제

#### 손실이 수렴하지 않음

**원인**: 학습률이 너무 높거나 낮음

**해결**:
1. 학습률 스케줄러 사용 (CosineAnnealing)
2. Warmup 적용
3. 그래디언트 클리핑 적용

#### 과적합 발생

**원인**: 데이터 부족 또는 모델 복잡도 과다

**해결**:
1. 데이터 증강 (회전, 스케일링)
2. Dropout 추가
3. 레이어 수 감소

### 9.2 추론 시 발생하는 문제

#### ONNX 로드 실패

**원인**: opset 버전 불일치

**해결**:
1. opset_version=14 이상 사용
2. ONNX Runtime 버전 업데이트

#### 지오메트리 타입 변경

**원인**: 오프셋이 너무 커서 좌표가 축소됨

**해결**:
1. offset_scale 파라미터 조정
2. 타입 검증 후 Buffer(0) 폴백 적용

---

## 10. 부록

### 10.1 학습 데이터 예시

```json
{
  "sample_id": "train_00001",
  "error_type": "self_intersection",
  "geometry_type": "Polygon",
  "original_wkt": "POLYGON((0 0, 10 0, 5 5, 10 10, 0 10, 5 5, 0 0))",
  "corrected_wkt": "POLYGON((0 0, 10 0, 10 10, 0 10, 0 0))",
  "original_coords": [[0,0], [10,0], [5,5], [10,10], [0,10], [5,5], [0,0]],
  "corrected_coords": [[0,0], [10,0], [10,10], [0,10], [0,0]]
}
```

### 10.2 참고 문서

- PyTorch 공식 문서: https://pytorch.org/docs/
- ONNX Runtime 문서: https://onnxruntime.ai/docs/
- SpatialCheckProMax 아키텍처 설계서

### 10.3 버전 이력

| 버전 | 날짜 | 변경 사항 |
|------|------|----------|
| 1.0 | 2026-01-04 | 초기 문서 작성 |

---

**문서 끝**

